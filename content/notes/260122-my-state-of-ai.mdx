export const metadata = {
  title: "My State of AI",
  publishDate: "2026-01-22 05:28",
  collection: "Random",
  type: "thought",
  tags: ["AI", "LLM", "Workflow", "OpenCode"],
  description: "Personal record of AI tools, models, and workflow in early 2026.",
};

<Callout type="info">
This note is regularly updated to track my AI tools, models, and workflow. See the changelog at the bottom for history.
</Callout>

## Current Stack

I use a combination of flagship models for complex reasoning and "free" models for exploration and long-running tasks.

### Flagship Models (Primary)
- **[Gemini 3 Flash](https://deepmind.google/models/gemini/flash/)**: My go-to for daily tasks because of its stability and its capability in front-end development.
- **[Claude 3.5 Sonnet](https://www.anthropic.com/news/claude-3-5-sonnet)**: Still the king for complex tasks and deep architecture reviews.

### OpenCode Models (Free Tier)
[OpenCode](https://opencode.ai/) supports a pay-as-you-go model, but also provides several [free models](https://opencode.ai/docs/zen/#pricing) that are surprisingly capable:

- **[Big Pickle](https://www.crackedaiengineering.com/ai-models/opencode-big-pickle)**: Large context window, good for reading documentation.
- **[Grok Code Fast 1](https://x.ai/news/grok-code-fast-1)**: Ultra-low latency, decent for quick snippets.
- **[MiniMax M2.1](https://huggingface.co/MiniMaxAI/MiniMax-M2.1)**: Balanced performance.
- **[GLM 4.7](https://huggingface.co/zai-org/GLM-4.7)**: Strong logic, though it can feel a bit robotic in style.

## My Thoughts & Observations

The free models provided by OpenCode don't feel as polished as the flagship models yet, but the gap is closing.

- **Usage Strategy**: I use OpenCode's free models for "weird experiments" or tasks where I need to iterate many times without worrying about cost.
- **Speed vs. Accuracy**: **Grok Code Fast 1** is incredibly fast but often breaks the code by failing to edit files properly (missing semicolons, multiple closing brackets, etc). It feels like early Copilot‚Äîgreat for autocomplete, risky for reliable refactoring.
- **Coding with GLM**: I've been using **GLM 4.7** heavily recently. It's surprisingly good at understanding context, though it lacks the "creativity" or nuance that Claude brings to the table.

<details>
<summary>üìù Changelog</summary>

### 2026-01-22
- Initial note created.
- Documented OpenCode free tier models (Big Pickle, Grok Code Fast 1, MiniMax M2.1, GLM 4.7).
- Switched primary models to Gemini 3 Flash and Claude 3.5 Sonnet.
- Added direct links to models and platforms.
- Refined observations for Grok Code Fast 1 accuracy.

</details>
